{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal Neural Networks (Tensorflow example)\n",
    "\n",
    "This jupyter notebook showcases how to utilize a [thermal neural network (TNN)](https://www.sciencedirect.com/science/article/pii/S0952197622005279) on an exemplary data set with the [Tensorflow](https://www.tensorflow.org/) framework.\n",
    "\n",
    "This example is concise for the sake of comprehensibility, that is, no cross-validation with a validation set is conducted, e.g., for early stopping, no learning rate scheduling, no repeated experiments with different random number generator seeds, etc.\n",
    "\n",
    "Feel free to build and expand your training pipeline on top of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set can be downloaded from [Kaggle](https://www.kaggle.com/wkirgsn/electric-motor-temperature).\n",
    "It should be placed in `data/input/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = Path().cwd() / \"data\" / \"input\" / \"measures_v2.csv\"\n",
    "data = pd.read_csv(path_to_csv)\n",
    "target_cols = [\"pm\", \"stator_yoke\", \"stator_tooth\", \"stator_winding\"]\n",
    "\n",
    "temperature_cols = target_cols + [\"ambient\", \"coolant\"]\n",
    "test_profiles = [60, 62, 74]\n",
    "train_profiles = [p for p in data.profile_id.unique() if p not in test_profiles]\n",
    "profile_sizes = data.groupby(\"profile_id\").agg(\"size\")\n",
    "\n",
    "# normalize\n",
    "non_temperature_cols = [c for c in data if c not in temperature_cols + [\"profile_id\"]]\n",
    "data.loc[:, temperature_cols] /= 200  # deg C\n",
    "data.loc[:, non_temperature_cols] /= data.loc[:, non_temperature_cols].abs().max(axis=0)\n",
    "\n",
    "# extra feats (FE)\n",
    "if {\"i_d\", \"i_q\", \"u_d\", \"u_q\"}.issubset(set(data.columns.tolist())):\n",
    "    extra_feats = {\n",
    "        \"i_s\": lambda x: np.sqrt((x[\"i_d\"] ** 2 + x[\"i_q\"] ** 2)),\n",
    "        \"u_s\": lambda x: np.sqrt((x[\"u_d\"] ** 2 + x[\"u_q\"] ** 2)),\n",
    "    }\n",
    "data = data.assign(**extra_feats)\n",
    "input_cols = [c for c in data.columns if c not in target_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange features\n",
    "input_cols = [c for c in data.columns if c not in target_cols + [\"profile_id\"]]\n",
    "data = data.loc[:, input_cols + [\"profile_id\"] + target_cols]\n",
    "\n",
    "\n",
    "def generate_tensor(profiles_list):\n",
    "    \"\"\"Returns profiles of the data set in a coherent 3D tensor with\n",
    "    time-major shape (T, B, F) where\n",
    "    T : Maximum profile length\n",
    "    B : Batch size = Amount of profiles\n",
    "    F : Amount of input features.\n",
    "\n",
    "    Also returns a likewise-shaped sample_weights tensor, which zeros out post-padded zeros for use\n",
    "    in the cost function (i.e., it acts as masking tensor)\"\"\"\n",
    "\n",
    "    tensor = np.full(\n",
    "        (profile_sizes[profiles_list].max(), len(profiles_list), data.shape[1] - 1),\n",
    "        np.nan,\n",
    "    )\n",
    "    for i, (pid, df) in enumerate(\n",
    "        data.loc[data.profile_id.isin(profiles_list), :].groupby(\"profile_id\")\n",
    "    ):\n",
    "        assert pid in profiles_list, f\"PID is not in {profiles_list}!\"\n",
    "        tensor[: len(df), i, :] = df.drop(columns=\"profile_id\").to_numpy()\n",
    "    sample_weights = 1 - np.isnan(tensor[:, :, 0])\n",
    "    tensor = np.nan_to_num(tensor).astype(np.float32)\n",
    "    tensor = tf.convert_to_tensor(tensor)\n",
    "    sample_weights = tf.convert_to_tensor(sample_weights)\n",
    "    return tensor, sample_weights\n",
    "\n",
    "\n",
    "train_tensor, train_sample_weights = generate_tensor(train_profiles)\n",
    "test_tensor, test_sample_weights = generate_tensor(test_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with RNNs in tensorflow:\n",
    "#  https://www.tensorflow.org/guide/keras/working_with_rnns\n",
    "\n",
    "\n",
    "class TNNCell(tf.keras.layers.Layer):\n",
    "    \"\"\"The main TNN logic. Here, the sub-NNs are initialized as well as the constant learnable\n",
    "    thermal capacitances. The forward function houses the LPTN ODE discretized with the explicit Euler method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sample_time = 0.5  # in s\n",
    "        self.state_size = len(target_cols)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # log inverse capacitances\n",
    "        #   hand-picked init mean, might be application-dependent\n",
    "        self.caps = self.add_weight(\n",
    "            shape=(input_shape[-1], self.state_size),\n",
    "            initializer=tf.keras.initializers.RandomNormal(mean=-9.2, stddev=0.5),\n",
    "        )\n",
    "\n",
    "        n_temps = len(temperature_cols)  # number of temperatures (targets and input)\n",
    "        n_conds = int(0.5 * n_temps * (n_temps - 1))  # number of thermal conductances\n",
    "        # conductance net sub-NN\n",
    "        self.conductance_net = tf.keras.models.Sequential(\n",
    "            tf.keras.layers.Dense(\n",
    "                (input_shape[-1] + self.state_size, n_conds), activation=\"sigmoid\"\n",
    "            )\n",
    "        )\n",
    "        # populate adjacency matrix. It is used for indexing the conductance sub-NN output\n",
    "        self.adj_mat = np.zeros((n_temps, n_temps), dtype=int)\n",
    "        adj_idx_arr = np.ones_like(self.adj_mat)\n",
    "        triu_idx = np.triu_indices(n_temps, 1)\n",
    "        adj_idx_arr = adj_idx_arr[triu_idx].ravel()\n",
    "        self.adj_mat[triu_idx] = np.cumsum(adj_idx_arr) - 1\n",
    "        self.adj_mat += self.adj_mat.T\n",
    "        self.adj_mat = tf.convert_to_tensor(\n",
    "            self.adj_mat[: self.state_size, :], dtype=tf.int64\n",
    "        )\n",
    "        self.n_temps = n_temps\n",
    "\n",
    "        # power loss sub-NN\n",
    "        self.ploss = tf.keras.models.Sequential(\n",
    "            tf.keras.layers.Dense(\n",
    "                (len(input_cols) + self.state_size, 16), activation=\"tanh\"\n",
    "            ),\n",
    "            tf.keras.layers.Dense((16, self.state_size)),\n",
    "        )\n",
    "\n",
    "        self.temp_idcs = [i for i, x in enumerate(input_cols) if x in temperature_cols]\n",
    "        self.nontemp_idcs = [\n",
    "            i\n",
    "            for i, x in enumerate(input_cols)\n",
    "            if x not in temperature_cols + [\"profile_id\"]\n",
    "        ]\n",
    "\n",
    "    def get_initial_state(inputs=None, batch_size=None, dtype=None):\n",
    "        \"\"\"This function should be fed with the target tensor instead of the input tensor\"\"\"\n",
    "        return inputs[0, :, :]\n",
    "\n",
    "    def call(self, input_at_t, states_at_t):\n",
    "        output_at_t = states_at_t\n",
    "        temps = tf.concat([output_at_t, input_at_t[:, self.temp_idcs]], axis=1)\n",
    "        sub_nn_inp = tf.concat([input_at_t, output_at_t], axis=1)\n",
    "        conducts = tf.abs(self.conductance_net(sub_nn_inp))\n",
    "        power_loss = tf.abs(self.ploss(sub_nn_inp))\n",
    "        heat_transfer_from_temp_diffs = tf.math.reduce_sum(\n",
    "            (tf.expand_dims(temps, axis=1) - tf.expand_dims(output_at_t, axis=-1))\n",
    "            * conducts[:, self.adj_mat],\n",
    "            axis=-1,\n",
    "        )\n",
    "        states_at_t_plus_1 = output_at_t + self.sample_time * tf.exp(self.caps) * (\n",
    "            heat_transfer_from_temp_diffs + power_loss\n",
    "        )\n",
    "        return output_at_t, tf.clip(states_at_t_plus_1, -1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = TNNCell()\n",
    "model = tf.keras.layers.RNN(cell, return_sequences=True, time_major=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 16\u001b[0m         output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tensor\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtbptt_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtbptt_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_func(\n\u001b[1;32m     23\u001b[0m             output,\n\u001b[1;32m     24\u001b[0m             train_tensor[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39mtrain_sample_weights,\n\u001b[1;32m     28\u001b[0m         )\n\u001b[1;32m     29\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mvariables)\n",
      "File \u001b[0;32m~/dev/tools/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/rnn/base_rnn.py:626\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstants\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m constants\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/tools/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mTNNCell.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     24\u001b[0m n_conds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m n_temps \u001b[38;5;241m*\u001b[39m (n_temps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# number of thermal conductances\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# conductance net sub-NN\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconductance_net \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_conds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# populate adjacency matrix. It is used for indexing the conductance sub-NN output\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_temps, n_temps), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'tuple'"
     ]
    }
   ],
   "source": [
    "loss_func = tf.keras.losses.MeanSquaredError()\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-3, clipvalue=1.0)\n",
    "#model.compile(optimizer=opt, loss=loss_func)\n",
    "n_epochs = 100\n",
    "tbptt_size = 32  # 512\n",
    "\n",
    "n_batches = np.ceil(train_tensor.shape[0] / tbptt_size).astype(int)\n",
    "with tqdm(desc=\"Training\", total=n_epochs) as pbar:\n",
    "    for epoch in range(n_epochs):\n",
    "        # first state is ground truth temperature data\n",
    "        hidden = train_tensor[0, :, -len(target_cols) :]\n",
    "\n",
    "        # propagate batch-wise through data set\n",
    "        for i in range(n_batches):\n",
    "            with tf.GradientTape() as tape:\n",
    "                output, hidden = model(\n",
    "                    inputs=train_tensor[\n",
    "                        i * tbptt_size : (i + 1) * tbptt_size, :, : len(input_cols)\n",
    "                    ],\n",
    "                    initial_state=(tf.stop_gradient(hidden), ),\n",
    "                )\n",
    "                loss = loss_func(\n",
    "                    output,\n",
    "                    train_tensor[\n",
    "                        i * tbptt_size : (i + 1) * tbptt_size, :, -len(target_cols) :\n",
    "                    ],\n",
    "                    sample_weight=train_sample_weights,\n",
    "                )\n",
    "            grads = tape.gradient(loss, model.variables)\n",
    "            opt.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_postfix_str(f\"loss: {loss.item():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
