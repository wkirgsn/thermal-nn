{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal Neural Networks (Tensorflow example)\n",
    "\n",
    "This jupyter notebook showcases how to utilize a [thermal neural network (TNN)](https://www.sciencedirect.com/science/article/pii/S0952197622005279) on an exemplary data set with the [Tensorflow](https://www.tensorflow.org/) framework.\n",
    "\n",
    "This example is concise for the sake of comprehensibility, that is, no cross-validation with a validation set is conducted, e.g., for early stopping, no learning rate scheduling, no repeated experiments with different random number generator seeds, etc.\n",
    "\n",
    "Feel free to build and expand your training pipeline on top of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set can be downloaded from [Kaggle](https://www.kaggle.com/wkirgsn/electric-motor-temperature).\n",
    "It should be placed in `data/input/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = Path().cwd() / \"data\" / \"input\" / \"measures_v2.csv\"\n",
    "data = pd.read_csv(path_to_csv)\n",
    "target_cols = [\"pm\", \"stator_yoke\", \"stator_tooth\", \"stator_winding\"]\n",
    "\n",
    "temperature_cols = target_cols + [\"ambient\", \"coolant\"]\n",
    "test_profiles = [60, 62, 74]\n",
    "train_profiles = [p for p in data.profile_id.unique() if p not in test_profiles]\n",
    "profile_sizes = data.groupby(\"profile_id\").agg(\"size\")\n",
    "\n",
    "# normalize\n",
    "non_temperature_cols = [c for c in data if c not in temperature_cols + [\"profile_id\"]]\n",
    "data.loc[:, temperature_cols] /= 200  # deg C\n",
    "data.loc[:, non_temperature_cols] /= data.loc[:, non_temperature_cols].abs().max(axis=0)\n",
    "\n",
    "# extra feats (FE)\n",
    "if {\"i_d\", \"i_q\", \"u_d\", \"u_q\"}.issubset(set(data.columns.tolist())):\n",
    "    extra_feats = {\n",
    "        \"i_s\": lambda x: np.sqrt((x[\"i_d\"] ** 2 + x[\"i_q\"] ** 2)),\n",
    "        \"u_s\": lambda x: np.sqrt((x[\"u_d\"] ** 2 + x[\"u_q\"] ** 2)),\n",
    "    }\n",
    "data = data.assign(**extra_feats)\n",
    "input_cols = [c for c in data.columns if c not in target_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange features\n",
    "input_cols = [c for c in data.columns if c not in target_cols + [\"profile_id\"]]\n",
    "data = data.loc[:, input_cols + [\"profile_id\"] + target_cols]\n",
    "\n",
    "\n",
    "def generate_tensor(profiles_list):\n",
    "    tensor = np.full(\n",
    "        (profile_sizes[profiles_list].max(), len(profiles_list), data.shape[1] - 1),\n",
    "        np.nan,\n",
    "    )\n",
    "    for i, (pid, df) in enumerate(\n",
    "        data.loc[data.profile_id.isin(profiles_list), :].groupby(\"profile_id\")\n",
    "    ):\n",
    "        assert pid in profiles_list, f\"PID is not in {profiles_list}!\"\n",
    "        tensor[: len(df), i, :] = df.drop(columns=\"profile_id\").to_numpy()\n",
    "    sample_weights = 1 - np.isnan(tensor[:, :, 0])\n",
    "    tensor = np.nan_to_num(tensor).astype(np.float32)\n",
    "    tensor = tf.convert_to_tensor(tensor)\n",
    "    sample_weights = tf.convert_to_tensor(sample_weights)\n",
    "    return tensor, sample_weights\n",
    "\n",
    "\n",
    "train_tensor, train_sample_weights = generate_tensor(train_profiles)\n",
    "test_tensor, test_sample_weights = generate_tensor(test_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with RNNs in tensorflow:\n",
    "#  https://www.tensorflow.org/guide/keras/working_with_rnns\n",
    "\n",
    "class TNNCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sample_time = 0.5  # in s\n",
    "        self.output_size = len(target_cols)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # inverse capacitances\n",
    "        #   hand-picked init mean, might be application-dependent\n",
    "        self.caps = self.add_weight(shape=(input_shape[-1], self.output_size),\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(mean=-9.2, stddev=0.5))\n",
    "\n",
    "        n_temps = len(temperature_cols)  # number of temperatures (targets and input)\n",
    "        n_conds = int(0.5 * n_temps * (n_temps - 1))  # number of thermal conductances\n",
    "        # conductance net sub-NN\n",
    "        self.conductance_net = tf.keras.models.Sequential(\n",
    "            tf.keras.layers.Dense((input_shape[-1] + self.output_size, n_conds), activation='sigmoid')\n",
    "        )\n",
    "        # populate adjacency matrix. It is used for indexing the conductance sub-NN output\n",
    "        self.adj_mat = np.zeros((n_temps, n_temps), dtype=int)\n",
    "        adj_idx_arr = np.ones_like(self.adj_mat)\n",
    "        triu_idx = np.triu_indices(n_temps, 1)\n",
    "        adj_idx_arr = adj_idx_arr[triu_idx].ravel()\n",
    "        self.adj_mat[triu_idx] = np.cumsum(adj_idx_arr) - 1\n",
    "        self.adj_mat += self.adj_mat.T\n",
    "        self.adj_mat = tf.convert_to_tensor(self.adj_mat[: self.output_size, :], dtype=tf.int64)\n",
    "        self.n_temps = n_temps\n",
    "\n",
    "        # power loss sub-NN\n",
    "        self.ploss = tf.keras.models.Sequential(\n",
    "            tf.keras.layers.Dense((len(input_cols) + self.output_size, 16), activation='tanh'),\n",
    "            tf.keras.layers.Dense((16, self.output_size)),\n",
    "        )\n",
    "\n",
    "        self.temp_idcs = [i for i, x in enumerate(input_cols) if x in temperature_cols]\n",
    "        self.nontemp_idcs = [\n",
    "            i\n",
    "            for i, x in enumerate(input_cols)\n",
    "            if x not in temperature_cols + [\"profile_id\"]\n",
    "        ]\n",
    "\n",
    "    def call(self):\n",
    "        # TODO implement further\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = TNNCell()\n",
    "model = tf.keras.layers.RNN(cell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
